{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c388708-afa7-4a33-b741-2a6af9533c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Concat all data files into one [Training] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/data-training/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/citationParser/data/\" + 'data-train-2M.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "datafiles = datafiles[0:350] # take 40 files to get sm\n",
    "print(len(datafiles))\n",
    "\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b48651-a20c-4a19-8667-25cda4e8701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Concat all data files into one [Validation] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/data-validation/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/GIANT/data/\" + 'data-validation.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8d5cfee-f41c-4538-ba3b-90c5687e382c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in ./envs/citationparser/lib/python3.7/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in ./envs/citationparser/lib/python3.7/site-packages (from bs4) (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./envs/citationparser/lib/python3.7/site-packages (from beautifulsoup4->bs4) (2.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b88154fa-1152-4814-832d-1270df539cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sickle in ./envs/citationparser/lib/python3.7/site-packages (0.7.0)\n",
      "Requirement already satisfied: requests>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from sickle) (2.25.1)\n",
      "Requirement already satisfied: lxml>=3.2.3 in ./envs/citationparser/lib/python3.7/site-packages (from sickle) (4.6.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=1.1.0->sickle) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./envs/citationparser/lib/python3.7/site-packages (from requests>=1.1.0->sickle) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=1.1.0->sickle) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=1.1.0->sickle) (2021.5.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6034f3bf-34f5-4b9a-b15d-e77a5ca931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Concat all data files into one [Testing code block] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/data-test/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/GIANT/data/\" + 'seethro.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0187eb1-df78-4e96-ab50-e691230361de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
