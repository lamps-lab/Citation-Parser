{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c388708-afa7-4a33-b741-2a6af9533c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Concat all data files into one [Training] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/downsized-1564-v2/Block-text-files/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/citationParser/data/\" + 'GIANT-1564-v2-train.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "#datafiles = datafiles[0:350] # take 40 files to get sm\n",
    "print(len(datafiles))\n",
    "\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37b48651-a20c-4a19-8667-25cda4e8701e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Concat all data files into one [Validation] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/data-validation/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/citationParser/data/\" + 'data-validation.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e79bf51-0472-496c-a21b-6511a504da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Concat all data files into one [Test] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/GIANT-test/Sample-three/BlockTokenizer/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/GIANT/GIANT-test/Sample-three/BlockTokenizer/concat/\" + 'GIANT-block-test.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6034f3bf-34f5-4b9a-b15d-e77a5ca931bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Concat all data files into one [Testing code block] \"\"\"\n",
    "\"\"\"\n",
    "    This code takes all the text files in a directory and merge them into one\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import string\n",
    "import random\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "dataDirectory = r\"/home/muddi004/muddi/GIANT/downsized-100/text-files/\"\n",
    "outputfilePath = r\"/home/muddi004/muddi/GIANT/downsized-100/text-files/cancat/\" + 'giant-test.txt'\n",
    "datafiles =  glob.glob(os.path.join(dataDirectory, \"*.txt\"))\n",
    "datafiles = datafiles[:300]\n",
    "with open(outputfilePath,'wb') as wfd:\n",
    "    for f in datafiles:#['seg1.txt','seg2.txt','seg3.txt']:\n",
    "        with open(f,'rb') as fd:\n",
    "            shutil.copyfileobj(fd, wfd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9325e5c9-db41-45df-9a84-48cc336d530e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seqeval in ./envs/citationparser/lib/python3.7/site-packages (1.2.2)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.7/site-packages (from seqeval) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.20.3)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.6.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=0.21.3->seqeval) (2.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/home/muddi004/envs/citationparser/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0187eb1-df78-4e96-ab50-e691230361de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         PER       1.00      1.00      1.00         2\n",
      "        PUNC       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.metrics import f1_score\n",
    "y_true = [['B-PER', 'I-PER', 'B-PUNC', 'I-PER']]\n",
    "y_pred = [['B-PER', 'I-PER', 'B-PUNC', 'I-PER']]\n",
    "#f1_score(y_true, y_pred)\n",
    "\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec203421-a1cf-4f83-8cd9-4e04a4097a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
